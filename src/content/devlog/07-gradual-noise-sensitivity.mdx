---
title: "Experiment 07: Gradual's Noise Collapse and the Optimal Forgiveness Rate"
date: 2026-02-28
description: "We implement the Gradual strategy (Mathieu & Delahaye 2002) — a proportional-retaliation rule that wins large deterministic tournaments — and test it for the first time under environmental noise. Gradual leads at ε=0 but its cooperation rate collapses from 100% to 26% at ε=0.05 when two Gradual players face each other. A companion forgiveness-rate sweep finds the noise-optimal forgiveness probability p* ≈ 0.10–0.20, not the canonical p=0.33, and identifies Tit for Two Tats as the most noise-robust cooperative strategy in our field."
tags: ["gradual", "noise", "forgiveness", "tit-for-two-tats", "generous-tft"]
---

import BarChart from "../../components/BarChart.astro";
import { runMany } from "../../lib/engine/stats";
import { playGame } from "../../lib/engine/game";
import { mulberry32 } from "../../lib/engine/rng";
import {
  allStrategies,
  makeGenTFT,
  gradual,
  titForTat,
  titForTwoTats,
  contriteTFT,
  allCooperate,
  allDefect,
  suspiciousTFT,
  zdExtorter,
  random,
} from "../../lib/strategies/index";

export const NOISE_LEVELS = [0, 0.01, 0.02, 0.05, 0.10];

export const sweepResults = NOISE_LEVELS.map(eps =>
  runMany(allStrategies, 200, 100, 0, eps)
);

export const rowOrder = sweepResults[0].stats.map(s => s.name);

export const allRanks = rowOrder.map(name =>
  sweepResults.map(r => r.stats.find(s => s.name === name).meanRank)
);

export const bestRankPerStrategy = allRanks.map(ranks =>
  ranks.reduce((min, r) => Math.min(min, r), Infinity)
);

export const SELF_PLAY_N = 50;
export const gradualSelfPlay = NOISE_LEVELS.map(eps =>
  Array(SELF_PLAY_N).fill(null)
    .map((_, seed) => playGame(gradual, gradual, 200, mulberry32(seed), eps))
    .reduce((sum, r) => sum + (r.coopRateA + r.coopRateB) / 2, 0) / SELF_PLAY_N * 100
);
export const tf2tSelfPlay = NOISE_LEVELS.map(eps =>
  Array(SELF_PLAY_N).fill(null)
    .map((_, seed) => playGame(titForTwoTats, titForTwoTats, 200, mulberry32(seed), eps))
    .reduce((sum, r) => sum + (r.coopRateA + r.coopRateB) / 2, 0) / SELF_PLAY_N * 100
);

export const baseField = [
  titForTat, titForTwoTats, gradual, contriteTFT,
  allCooperate, allDefect, suspiciousTFT, zdExtorter, random
];
export const PS = [0, 0.10, 0.20, 0.33, 0.50, 0.67, 0.80, 1.0];

export const forgResults = PS.map(p =>
  NOISE_LEVELS.map(eps =>
    runMany(baseField.concat([makeGenTFT(p)]), 200, 80, 0, eps).stats
      .find(s => s.name === ("GenTFT(p=" + p.toFixed(2) + ")")).meanRank
  )
);

export const bestRankPerP = forgResults.map(ranks =>
  ranks.reduce((min, r) => Math.min(min, r), Infinity)
);

## Research Question

Mathieu & Delahaye (2002, 2017) showed that **Gradual** — a strategy that retaliates
proportionally (k consecutive defections after the opponent's k-th cumulative defection,
then 2 calm cooperative rounds) — wins large diverse tournaments convincingly. This
result has been replicated in deterministic settings. But their tournaments assume
no noise. The question we ask today:

> **How does Gradual perform under environmental noise, and does its proportional
> punishment mechanism remain an asset when moves are occasionally misread?**

A companion experiment asks a quantitative question left open by Glynatsi et al. (2024):

> **What is the noise-optimal forgiveness probability p\* for Generous TFT, and does
> it match the canonical value of p=0.33?**

---

## The Gradual Strategy

Gradual's rule: cooperate by default, but after the opponent's k-th cumulative
defection, immediately begin a punishment burst of k consecutive defections, followed
by exactly 2 cooperative "calm" rounds before returning to normal. Any defections
observed during a punishment or calm phase increment the defection counter but do
not interrupt the current phase — they will be repaid in the next burst.

The result is an escalating but structured response: first defection → 1 D, 2 calm.
Second defection encountered after calm → punishment of 2D (or more, since defections
during calm count). The strategy "remembers" every transgression and delivers them all,
batched and measured.

Verified against AllDefect (200 rounds, deterministic, seed 1):

```
mine: C D C C D D D D C C D D D D D D D D C C ...
       ↑   ↑↑   calm   ↑↑↑↑     calm   ...
     round1 1D burst   4D burst (dTotal=4 during calm)
```

---

## Experiment A: Full-Field Tournament Across Noise Levels

### Mean Rank (lower = better, 100 seeds, 200 rounds/match, 12 strategies)

<table>
  <thead>
    <tr>
      <th>Strategy</th>
      {NOISE_LEVELS.map(eps => <th key={eps}>ε={eps}</th>)}
    </tr>
  </thead>
  <tbody>
    {rowOrder.map((name, ni) => (
      <tr key={name}>
        <td><strong>{name}</strong></td>
        {allRanks[ni].map((rank, i) => (
          <td key={i} style={`color: ${rank <= 2.5 ? "var(--green)" : rank >= 9 ? "var(--red)" : "var(--text)"}; font-weight: ${rank === bestRankPerStrategy[ni] ? "bold" : "normal"}`}>
            {rank.toFixed(2)}
          </td>
        ))}
      </tr>
    ))}
  </tbody>
</table>

### Finding A1: Gradual wins at ε=0, then collapses

At zero noise, Gradual ranks **1st** (mean rank 1.51), edging out Tit for Two Tats
(1.65). Proportional punishment is exactly the right response in a deterministic
world: it deters defection more effectively than TFT (which reacts identically to
one defection or many) while remaining perfectly cooperative against other cooperative
strategies.

But under noise, Gradual collapses sharply:
- ε=0.01: rank drops to 3.20 (behind TF2T and GenTFT)
- ε=0.02: rank 4.93 — now below TFT, Pavlov, and CTFT
- ε=0.05: rank 7.85 — near the bottom, below ZD Extorter and Suspicious TFT

### Finding A2: Tit for Two Tats is the most noise-robust cooperative strategy

TF2T, which requires two consecutive defections before retaliating, shows the
opposite trajectory — it *improves* relative to the field as noise increases:

| ε | TF2T mean rank |
|---|---------------|
| 0 | 1.65 |
| 0.01 | 2.10 |
| 0.02 | 1.46 |
| 0.05 | 1.30 |
| 0.10 | 4.40 |

TF2T stays in the top 2 across ε=0 through ε=0.05. Only at ε=0.10 — extreme noise —
does the cost of its leniency catch up, as strategies with more aggressive punishment
start scoring better against the chaos.

---

## Experiment B: The Noise-Feedback Mechanism

Why does Gradual collapse so severely? The self-play cooperation rate reveals the
mechanism directly.

### Self-play cooperation rate (50 seeds, 200 rounds/match)

<table>
  <thead>
    <tr>
      <th>ε</th>
      <th>Gradual vs Gradual</th>
      <th>TF2T vs TF2T</th>
    </tr>
  </thead>
  <tbody>
    {NOISE_LEVELS.map((eps, i) => (
      <tr key={eps}>
        <td>ε={eps}</td>
        <td style={`color: ${gradualSelfPlay[i] > 85 ? "var(--green)" : gradualSelfPlay[i] < 50 ? "var(--red)" : "var(--text)"}`}>
          {gradualSelfPlay[i].toFixed(1)}%
        </td>
        <td style={`color: ${tf2tSelfPlay[i] > 85 ? "var(--green)" : tf2tSelfPlay[i] < 50 ? "var(--red)" : "var(--text)"}`}>
          {tf2tSelfPlay[i].toFixed(1)}%
        </td>
      </tr>
    ))}
  </tbody>
</table>

Two Gradual players facing each other maintain 100% cooperation with no noise — but
at ε=0.01 their cooperation rate drops to ~60%, and at ε=0.05 to ~26%. TF2T pairs
hold above 94% even at ε=0.05.

**The mechanism:** When a noise event causes player A to appear to defect, player B
initiates a punishment burst. A, observing those retaliatory defections during its
own calm phase, increments its defection counter — scheduling a *longer* punishment
burst in response. B then does the same. Each noise event amplifies into an escalating
spiral of increasingly long punishment sequences. Because Gradual's punishment length
grows with cumulative defections, a single noise event has compounding effects across
dozens of subsequent rounds.

TF2T avoids this entirely. Requiring *two consecutive* apparent defections before
retaliating, it absorbs isolated noise events without responding. A single flipped
move — the most common noise event — never triggers punishment.

---

## Experiment C: Optimal Forgiveness Rate

The canonical Generous TFT uses p=0.33 (cooperates with 33% probability after
opponent defection). Glynatsi et al. (2024) ask whether the optimal forgiveness rate
varies with noise. We test p ∈ {0, 0.10, 0.20, 0.33, 0.50, 0.67, 0.80, 1.0} in
the 12-strategy field, measuring mean rank across 80 seeds.

### GenTFT(p) mean rank by noise level (lower = better)

<table>
  <thead>
    <tr>
      <th>p</th>
      <th>Strategy</th>
      {NOISE_LEVELS.map(eps => <th key={eps}>ε={eps}</th>)}
    </tr>
  </thead>
  <tbody>
    {PS.map((p, pi) => (
      <tr key={p}>
        <td>{p.toFixed(2)}</td>
        <td><strong>{"GenTFT(p=" + p.toFixed(2) + ")"}</strong></td>
        {forgResults[pi].map((rank, i) => (
          <td key={i} style={`color: ${rank <= 3 ? "var(--green)" : rank >= 8 ? "var(--red)" : "var(--text)"}; font-weight: ${rank === bestRankPerP[pi] ? "bold" : "normal"}`}>
            {rank.toFixed(2)}
          </td>
        ))}
      </tr>
    ))}
  </tbody>
</table>

### Finding C1: p\* ≈ 0.10–0.20, not the canonical 0.33

The winning forgiveness rate (per noise level) is:

| ε | Optimal p | Mean rank of winner |
|---|-----------|---------------------|
| 0 | 0.10 | 1.99 |
| 0.01 | 0.20 | 2.21 |
| 0.02 | 0.20 | 2.01 |
| 0.05 | 0.20 | 2.89 |
| 0.10 | 0.10 | 4.21 |

The canonical p=0.33 is suboptimal at every tested noise level. In a 12-strategy
field that includes Gradual, ZD Extorter, and Suspicious TFT, the pressure to punish
defections is high enough that higher forgiveness (p=0.33–0.50) consistently costs
GenTFT rank against exploitative opponents.

Across the noise range 0–0.05, p=0.20 is the most consistently strong choice:
- At ε=0: rank 2.48 (second to p=0.10)
- At ε=0.01–0.02: rank 2.21–2.01 (best overall)
- At ε=0.05: rank 2.89 (best overall)

The result suggests the widely-used canonical GenTFT (p=0.33) was calibrated against
smaller, less aggressive fields. In a field with the strategies we study, 0.20 is the
noise-robust optimum.

### Finding C2: There is a forgiveness cliff above p=0.50

Above p=0.50, mean rank degrades rapidly at high noise. At ε=0.10, p=0.50 drops to
rank 10.0 and p=0.80 to rank 11.2. The reason mirrors Gradual's collapse: very high
forgiveness looks like AllCooperate to exploitative strategies (ZD Extorter, AllDefect),
and those strategies score well at high noise when cooperative strategies can't
coordinate punishment reliably.

---

## Summary

Two findings from this experiment are not in the prior literature:

**1. Gradual has never been tested under noise, and fails badly.** Its proportional
punishment mechanism creates a noise-amplification feedback: single flipped moves
cascade into long escalating punishment cycles between two Gradual players. The
cooperation rate collapses from 100% at ε=0 to 26% at ε=0.05. Tournament rank falls
from 1st to near-last.

**2. The noise-optimal forgiveness rate for Generous TFT is p\* ≈ 0.20, not the
canonical 0.33.** The canonical value was derived from small deterministic fields.
In a 12-strategy field including Gradual, ZD Extorter, and Suspicious TFT, lower
forgiveness (p=0.10–0.20) consistently outranks p=0.33 at every tested noise level.

The surprise is Tit for Two Tats. It was not designed for noisy environments — yet it
outperforms both GenTFT and TFT at ε=0.01 through ε=0.05. Its "require two consecutive
defections" rule is a natural noise filter. Whether this advantage survives evolutionary
pressure is the next question.

---

## Next Steps

**E-008: Evolutionary noise robustness of TF2T.** The round-robin tournament shows
TF2T is the most noise-robust cooperative strategy in our field. But tournament rank
and evolutionary fitness are different measures. In E-003 we showed that GenTFT
dominates evolutionarily. Does TF2T's tournament advantage translate to evolutionary
dominance under noise, or does GenTFT's better self-play against cooperative partners
give it a replicator advantage that TF2T cannot match?

The specific question: at ε=0.02, does TF2T or GenTFT win the replicator dynamics,
and does that answer change at ε=0.05?
